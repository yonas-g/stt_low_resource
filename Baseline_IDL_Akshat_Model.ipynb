{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "75051afa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from torch.utils.data import DataLoader\n",
    "import json\n",
    "# from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "from utils.data import *\n",
    "from utils.models import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0e803af5",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = PHONE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "11868c79",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(path_to_data, speakers, recordings, voices, classes, less_prob = False, closeness=2):\n",
    "        X = []\n",
    "        Y = []\n",
    "        for speaker in speakers:\n",
    "            for record in recordings.keys():\n",
    "                for voice in voices:\n",
    "                    x_path = path_to_data+str(speaker)+\"/spchdatadir/recording\"+str(record)+\"/voice_\"+str(voice)+\".wav\"\n",
    "                    if less_prob:\n",
    "                        transcript_second = get_less_probable(x_path, closeness)\n",
    "                        transcript = get_transcript(x_path)\n",
    "                        index = np.random.randint(low=1, high=len(transcript), size=2)\n",
    "                        for ix  in index:\n",
    "                            transcript[ix] = transcript_second[ix]\n",
    "                    else:\n",
    "                        transcript = get_transcript(x_path)\n",
    "                    X.append(transcript)\n",
    "                    Y.append(classes[recordings[record]])\n",
    "        return X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8a654d4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GarboSamples(torch.utils.data.Dataset):\n",
    "\n",
    "    def __init__(self, path_to_data, speakers, voices, recordings, classes, less_prob = False, closeness=2): # You can use partition to specify train or dev\n",
    "        self.Xs, self.Ys = get_data(path_to_data, speakers, recordings, voices, classes, less_prob, closeness)\n",
    "        assert(len(self.Xs) == len(self.Ys))\n",
    "        self.length = len(self.Xs)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.length\n",
    "\n",
    "    def __getitem__(self, ind):\n",
    "\n",
    "        X = self.Xs[ind]\n",
    "        Y = self.Ys[ind]\n",
    "\n",
    "        Yy = torch.tensor(Y, dtype=torch.long).view(-1)\n",
    "        Xx = torch.from_numpy(X).long()\n",
    "        return Xx, Yy\n",
    "\n",
    "    def collate_fn(self, batch):\n",
    "\n",
    "        batch_x = [x for x, y in batch]\n",
    "        batch_y = [y for x, y in batch]\n",
    "\n",
    "        batch_x_pad = pad_sequence(batch_x, batch_first=True)\n",
    "        lengths_x = [len(x) for x in batch_x]\n",
    "        \n",
    "        batch_y_pad = pad_sequence(batch_y, batch_first=True) \n",
    "        lengths_y = [len(y) for y in batch_y] \n",
    "\n",
    "        return batch_x_pad, batch_y_pad, torch.tensor(lengths_x).type(torch.int), torch.tensor(lengths_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "437923e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_it_all(S, K, num_intents):\n",
    "        path_to_data = \"Data/Speakers/pp\"\n",
    "        train_speakers = range(2,S)\n",
    "        val_speakers = [9, 10]\n",
    "        test_speakers = [11, 12]\n",
    "        two_intent_recordings = {29:\"Lift\",\n",
    "                1:\"Approach\"}\n",
    "        four_intent_recordings = {\n",
    "                29:\"Lift\",\n",
    "                1:\"Approach\",\n",
    "                33:\"Grap\", \n",
    "                36:\"Point\"\n",
    "        }\n",
    "        classes = {\"Lift\":0, \n",
    "                \"Grap\":3, \n",
    "                \"Point\":2, \n",
    "                \"Approach\":1}\n",
    "        voices = np.random.randint(low=1, high=14, size=K)\n",
    "        less_prob = True\n",
    "        closeness = 2\n",
    "        BATCH_SIZE=4\n",
    "        if num_intents == 2:\n",
    "                rcrd = two_intent_recordings\n",
    "        else:\n",
    "                rcrd = four_intent_recordings\n",
    "        train_data = GarboSamples(path_to_data,train_speakers, voices, rcrd, classes, less_prob, closeness)\n",
    "        val_data = GarboSamples(path_to_data,val_speakers, voices, rcrd, classes, less_prob, closeness)\n",
    "        test_data = GarboSamples(path_to_data, test_speakers, voices, rcrd, classes, less_prob, closeness)\n",
    "        train_loader = DataLoader(train_data, batch_size=BATCH_SIZE, shuffle=True, collate_fn=train_data.collate_fn)\n",
    "        val_loader = DataLoader(val_data, batch_size=BATCH_SIZE, shuffle=True, collate_fn=val_data.collate_fn)\n",
    "        test_loader = DataLoader(test_data, batch_size=BATCH_SIZE, shuffle=False, collate_fn=test_data.collate_fn)\n",
    "\n",
    "        epochs = 20\n",
    "        model=ICASSP1CNN(229,label_size=num_intents)\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
    "        scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=(len(train_loader) * epochs))\n",
    "\n",
    "        for epoch in range(epochs):\n",
    "                model.train()\n",
    "                total_loss = 0\n",
    "                num_corrects = 0\n",
    "                for i, data in enumerate(train_loader):\n",
    "                        x, y, lx, ly = data\n",
    "\n",
    "                        optimizer.zero_grad()\n",
    "                        output = model(x,lx)\n",
    "\n",
    "                        loss = criterion(output, y.flatten())\n",
    "                        total_loss+=float(loss)\n",
    "\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                        num_corrects += int((torch.argmax(output, axis=1) == y.flatten()).sum())\n",
    "\n",
    "                        scheduler.step()\n",
    "\n",
    "                        del x\n",
    "                        del y\n",
    "                        del loss\n",
    "        total_loss=0\n",
    "        num_corrects = 0\n",
    "        for i,data in enumerate(val_loader):\n",
    "                x,y,lx,ly = data\n",
    "                with torch.no_grad():\n",
    "                        output = model(x,lx)\n",
    "                        \n",
    "                loss = criterion(output, y.flatten())\n",
    "                total_loss+=float(loss)\n",
    "                num_corrects += int((torch.argmax(output, axis=1) == y.flatten()).sum())\n",
    "\n",
    "                del x\n",
    "                del y\n",
    "                del loss\n",
    "\n",
    "        predictions = []\n",
    "        total_loss=0\n",
    "        num_corrects = 0\n",
    "        for i, data in enumerate(test_loader):\n",
    "                x,y,lx,ly = data\n",
    "                with torch.no_grad():\n",
    "                        output = model(x,lx)\n",
    "                \n",
    "                pred = np.argmax(output.detach().numpy(), axis=1)\n",
    "                predictions.append(pred)\n",
    "                num_corrects += int((torch.argmax(output, axis=1) ==y.flatten()).sum())\n",
    "\n",
    "                del x\n",
    "                del y\n",
    "        return float(100 * num_corrects / (len(test_loader) * BATCH_SIZE))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98b5031b",
   "metadata": {},
   "outputs": [],
   "source": [
    "log = {}\n",
    "for s in [6, 7, 8, 9]:\n",
    "    for k in range(1, 8):\n",
    "        scores = []\n",
    "        for i in range(3):\n",
    "            scores.append(do_it_all(s, k, num_intents=4))\n",
    "        avg_scores = np.mean(scores)\n",
    "        print(\"S: {}, k:{}, 3 exp Test Accuracy is {:0.4f}\".format(s-2, k, avg_scores))\n",
    "        log[\"S: {}, k:{}\".format(s-2, k)] = avg_scores\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15d1c49c",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_file = open(\"NAME OF EXP.json\", \"w\")\n",
    "json.dump(log, log_file)\n",
    "log_file.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
